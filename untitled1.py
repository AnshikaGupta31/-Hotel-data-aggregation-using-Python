# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cez4KKKdy13o2i-VxlvN1qA27_i9_5Vr
"""

# Steps for aggregation of  hotel franchise data from 50+ websitesusing Python libraries


import requests
from bs4 import BeautifulSoup as bs
import pandas as pd

#creating a function with a variable Indian hotel
def all_links(hotel):
  url1='https://www.meetings-conventions.com/Meeting-Event-Venues/Venue-Search?pst='+hotel+'%20india&typ=HOT&rm=0&cls=0&mspc=0&ff=1'
  response=requests.get(url1)
  soup= bs(response.text,'html.parser')
  #main parent table extraction ul= user list
  ul_element=soup.find('ul',class_='results')
  #extarction of li_elemnts which were stored in ul_element
  li_elements=ul_element.find_all('li')
  href_link=[]
  for li in li_elements:
    #extraction of each li tag
    a_tag = li.find("a")
    # to check whether each a_tag contains href or not
    if a_tag and "href" in a_tag.attrs:
      href = a_tag["href"]
      link="https://www.meetings-conventions.com/"+str(href)
      href_link.append(link)
  # print(href_link)
  # print(len(href_link))

  #iterating through the href_links
  df_dummy=pd.DataFrame()
  df_dummy['Hotel']=href_link
  # df['URL']=[i]

  df_final=pd.DataFrame()
  included_list=['Hotel','Name','Address','Phone', 'Web', 'Email', 'Year Built', 'Number of Floors','Total Number of Rooms','Chain','Chain Website','Guest Rooms','Meeting Rooms','Largest Conference Room	Room Rate','Total Event Space']
  for i in included_list:
    df_final[i]=[]

  for ix,link in enumerate(df_dummy['Hotel']):
    url=link

#extraction of href links
    response=requests.get(url)
    soup=bs(response.text,'html.parser')
    # print(soup)
    key_list=[]
    values_list=[]

    #1st ATTR
    Name=soup.find('h1',class_="heading-2").get_text().strip()
    # print(Name)
    # len(Name)
    key_list.append('Name')
    values_list.append(Name)

    # # 2nd ATTR
    div_class2 = 'venue-section venue-section--facts'  # Replace with the actual class name
    div_id2 = 'key-facts'
    div_element2 = soup.find('div', class_=div_class2, id=div_id2)
    dt_elements2 = div_element2.find_all('dt')
    dd_elements2 = div_element2.find_all('dd')
    # Extract the text data from <dd> and <dt> elements
    for dt, dd in zip(dt_elements2, dd_elements2):
        dt_text2 = dt.get_text().strip()
        dd_text2 = dd.get_text().strip()

        # Print or process the <dt> and <dd> data
        # print(f'dt: {dt_text2}')
        # print(f'dd: {dd_text2}')
        key_list.append(dt_text2)
        values_list.append(dd_text2)



    #3rd ATTR
    div_class3 = 'venue-section venue-section--overview'  # Replace with the actual class name
    div_id3 = 'overview'
    div_element3 = soup.find('div', class_=div_class3, id=div_id3)
    dd_elements3 = div_element3.find_all('dd')
    dt_elements3 = div_element3.find_all('dt')

    # Extract the text data from <dd> and <dt> elements
    for dt, dd in zip(dt_elements3, dd_elements3):
        dt_text3 = dt.get_text().strip()
        dd_text3 = dd.get_text().strip()

        # Print or process the <dt> and <dd> data
        # print(f'dt: {dt_text3}')
        # print(f'dd: {dd_text3}')
        key_list.append(dt_text3)
        values_list.append(dd_text3)

    #4TH ATTR
    div_class4 = 'venue-info'  # Replace with the actual class name
    div_element4 = soup.find('div', class_=div_class4)

    # Extract the <strong> data within the specific <div> element
    strong_elements4 = div_element4.select('strong')

    # Extract the text data from <strong> elements
    for strong in strong_elements4:
        strong_text4 = strong.get_text().strip()
        strong_value4 = strong.next_sibling.strip()
        # Print or process the <strong> data
        # print(f'strong: {strong_text4}')
        # print(f'value: {strong_value4}')
        key_list.append(strong_text4)
        values_list.append(strong_value4)

    #5TH ATTR
    div_class5 = 'venue-section venue-section--meeting-space'  # Replace with the actual class name
    div_id5 = 'meeting-rooms'
    div_element5 = soup.find('div', class_=div_class5, id=div_id5)
    dd_elements5 = div_element5.find_all('dd')
    dt_elements5 = div_element5.find_all('dt')

    # Extract the text data from <dd> and <dt> elements
    for dt, dd in zip(dt_elements5, dd_elements5):
        dt_text5 = dt.get_text().strip()
        dd_text5 = dd.get_text().strip()

        # Print or process the <dt> and <dd> data
        # print(f'dt: {dt_text5}')
        # print(f'dd: {dd_text5}')
        key_list.append(dd_text5)
        values_list.append(dd_text5)

    # print(key_list)
    # print(values_list)
    # print(len(key_list))
    # print(len(values_list))



    #creating a dictionary
    my_dict = dict(zip(key_list, values_list))


    df=pd.DataFrame()

    # included_list=['Hotel','Name','Address','Phone', 'Web', 'Email', 'Year Built', 'Number of Floors','Total Number of Rooms','Chain','Chain Website','Guest Rooms','Meeting Rooms','Largest Conference Room	Room Rate','Total Event Space']

#how to extract values from dictionary to dataframe
    df_columns=list(included_list)
    for i in my_dict.keys(): #from keys
      for j in df_columns:
        if i==j:
          df.loc[ix,i]= my_dict.get(i) #extraction of values



    for i in included_list:
      df_final.loc[ix, i]=my_dict.get(i)
    df_final.loc[ix, 'Hotel']=link      # from the df_dummy for loop which is the main loop from index ix


  # print(df.head())
  df_final.to_csv(f'{hotel}.csv')
  print(df_final.head())

all_links('taj')