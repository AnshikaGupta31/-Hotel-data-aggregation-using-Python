{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQk0jZZLDQ7b"
      },
      "outputs": [],
      "source": [
        "# Steps for aggregation of  hotel franchise data from 50+ websitesusing Python libraries\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import pandas as pd\n",
        "\n",
        "#creating a function with a variable Indian hotel\n",
        "def all_links(hotel):\n",
        "  url1='https://www.meetings-conventions.com/Meeting-Event-Venues/Venue-Search?pst='+hotel+'%20india&typ=HOT&rm=0&cls=0&mspc=0&ff=1'\n",
        "  response=requests.get(url1)\n",
        "  soup= bs(response.text,'html.parser')\n",
        "  #main parent table extraction ul= user list\n",
        "  ul_element=soup.find('ul',class_='results')\n",
        "  #extarction of li_elemnts which were stored in ul_element\n",
        "  li_elements=ul_element.find_all('li')\n",
        "  href_link=[]\n",
        "  for li in li_elements:\n",
        "    #extraction of each li tag\n",
        "    a_tag = li.find(\"a\")\n",
        "    # to check whether each a_tag contains href or not\n",
        "    if a_tag and \"href\" in a_tag.attrs:\n",
        "      href = a_tag[\"href\"]\n",
        "      link=\"https://www.meetings-conventions.com/\"+str(href)\n",
        "      href_link.append(link)\n",
        "  # print(href_link)\n",
        "  # print(len(href_link))\n",
        "\n",
        "  #iterating through the href_links\n",
        "  df_dummy=pd.DataFrame()\n",
        "  df_dummy['Hotel']=href_link\n",
        "  # df['URL']=[i]\n",
        "\n",
        "  df_final=pd.DataFrame()\n",
        "  included_list=['Hotel','Name','Address','Phone', 'Web', 'Email', 'Year Built', 'Number of Floors','Total Number of Rooms','Chain','Chain Website','Guest Rooms','Meeting Rooms','Largest Conference Room\tRoom Rate','Total Event Space']\n",
        "  for i in included_list:\n",
        "    df_final[i]=[]\n",
        "\n",
        "  for ix,link in enumerate(df_dummy['Hotel']):\n",
        "    url=link\n",
        "\n",
        "#extraction of href links\n",
        "    response=requests.get(url)\n",
        "    soup=bs(response.text,'html.parser')\n",
        "    # print(soup)\n",
        "    key_list=[]\n",
        "    values_list=[]\n",
        "\n",
        "    #1st ATTR\n",
        "    Name=soup.find('h1',class_=\"heading-2\").get_text().strip()\n",
        "    # print(Name)\n",
        "    # len(Name)\n",
        "    key_list.append('Name')\n",
        "    values_list.append(Name)\n",
        "\n",
        "    # # 2nd ATTR\n",
        "    div_class2 = 'venue-section venue-section--facts'  # Replace with the actual class name\n",
        "    div_id2 = 'key-facts'\n",
        "    div_element2 = soup.find('div', class_=div_class2, id=div_id2)\n",
        "    dt_elements2 = div_element2.find_all('dt')\n",
        "    dd_elements2 = div_element2.find_all('dd')\n",
        "    # Extract the text data from <dd> and <dt> elements\n",
        "    for dt, dd in zip(dt_elements2, dd_elements2):\n",
        "        dt_text2 = dt.get_text().strip()\n",
        "        dd_text2 = dd.get_text().strip()\n",
        "\n",
        "        # Print or process the <dt> and <dd> data\n",
        "        # print(f'dt: {dt_text2}')\n",
        "        # print(f'dd: {dd_text2}')\n",
        "        key_list.append(dt_text2)\n",
        "        values_list.append(dd_text2)\n",
        "\n",
        "\n",
        "\n",
        "    #3rd ATTR\n",
        "    div_class3 = 'venue-section venue-section--overview'  # Replace with the actual class name\n",
        "    div_id3 = 'overview'\n",
        "    div_element3 = soup.find('div', class_=div_class3, id=div_id3)\n",
        "    dd_elements3 = div_element3.find_all('dd')\n",
        "    dt_elements3 = div_element3.find_all('dt')\n",
        "\n",
        "    # Extract the text data from <dd> and <dt> elements\n",
        "    for dt, dd in zip(dt_elements3, dd_elements3):\n",
        "        dt_text3 = dt.get_text().strip()\n",
        "        dd_text3 = dd.get_text().strip()\n",
        "\n",
        "        # Print or process the <dt> and <dd> data\n",
        "        # print(f'dt: {dt_text3}')\n",
        "        # print(f'dd: {dd_text3}')\n",
        "        key_list.append(dt_text3)\n",
        "        values_list.append(dd_text3)\n",
        "\n",
        "    #4TH ATTR\n",
        "    div_class4 = 'venue-info'  # Replace with the actual class name\n",
        "    div_element4 = soup.find('div', class_=div_class4)\n",
        "\n",
        "    # Extract the <strong> data within the specific <div> element\n",
        "    strong_elements4 = div_element4.select('strong')\n",
        "\n",
        "    # Extract the text data from <strong> elements\n",
        "    for strong in strong_elements4:\n",
        "        strong_text4 = strong.get_text().strip()\n",
        "        strong_value4 = strong.next_sibling.strip()\n",
        "        # Print or process the <strong> data\n",
        "        # print(f'strong: {strong_text4}')\n",
        "        # print(f'value: {strong_value4}')\n",
        "        key_list.append(strong_text4)\n",
        "        values_list.append(strong_value4)\n",
        "\n",
        "    #5TH ATTR\n",
        "    div_class5 = 'venue-section venue-section--meeting-space'  # Replace with the actual class name\n",
        "    div_id5 = 'meeting-rooms'\n",
        "    div_element5 = soup.find('div', class_=div_class5, id=div_id5)\n",
        "    dd_elements5 = div_element5.find_all('dd')\n",
        "    dt_elements5 = div_element5.find_all('dt')\n",
        "\n",
        "    # Extract the text data from <dd> and <dt> elements\n",
        "    for dt, dd in zip(dt_elements5, dd_elements5):\n",
        "        dt_text5 = dt.get_text().strip()\n",
        "        dd_text5 = dd.get_text().strip()\n",
        "\n",
        "        # Print or process the <dt> and <dd> data\n",
        "        # print(f'dt: {dt_text5}')\n",
        "        # print(f'dd: {dd_text5}')\n",
        "        key_list.append(dd_text5)\n",
        "        values_list.append(dd_text5)\n",
        "\n",
        "    # print(key_list)\n",
        "    # print(values_list)\n",
        "    # print(len(key_list))\n",
        "    # print(len(values_list))\n",
        "\n",
        "\n",
        "\n",
        "    #creating a dictionary\n",
        "    my_dict = dict(zip(key_list, values_list))\n",
        "\n",
        "\n",
        "    df=pd.DataFrame()\n",
        "\n",
        "    # included_list=['Hotel','Name','Address','Phone', 'Web', 'Email', 'Year Built', 'Number of Floors','Total Number of Rooms','Chain','Chain Website','Guest Rooms','Meeting Rooms','Largest Conference Room\tRoom Rate','Total Event Space']\n",
        "\n",
        "#how to extract values from dictionary to dataframe\n",
        "    df_columns=list(included_list)\n",
        "    for i in my_dict.keys(): #from keys\n",
        "      for j in df_columns:\n",
        "        if i==j:\n",
        "          df.loc[ix,i]= my_dict.get(i) #extraction of values\n",
        "\n",
        "\n",
        "\n",
        "    for i in included_list:\n",
        "      df_final.loc[ix, i]=my_dict.get(i)\n",
        "    df_final.loc[ix, 'Hotel']=link      # from the df_dummy for loop which is the main loop from index ix\n",
        "\n",
        "\n",
        "  # print(df.head())\n",
        "  df_final.to_csv(f'{hotel}.csv')\n",
        "  print(df_final.head())\n",
        "\n",
        "all_links('taj')\n",
        "\n",
        "\n"
      ]
    }
  ]
}
